import os
import io
import time
import smtplib
import requests
import google.generativeai as genai
from pypdf import PdfReader
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta, timezone
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials 

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • (GitHub Secrets ì—°ë™)
# ==========================================

# GitHub Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
GOOGLE_SEARCH_API_KEY = os.environ.get("GOOGLE_SEARCH_API_KEY")
SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID")
GMAIL_USER = os.environ.get("GMAIL_USER")
GMAIL_APP_PWD = os.environ.get("GMAIL_APP_PWD")

# ìˆ˜ì‹ ì ëª©ë¡
def get_active_subscribers():
    print("ğŸ“‹ êµ¬ë…ì ëª…ë‹¨ í™•ì¸ ì¤‘...")
    
    # 1. GitHub Secretsì—ì„œ JSON í‚¤ ê°€ì ¸ì˜¤ê¸°
    json_str = os.environ.get("GCP_SERVICE_ACCOUNT_JSON")
    
    if not json_str:
        print("âš ï¸ ê²½ê³ : GCP_SERVICE_ACCOUNT_JSON ì‹œí¬ë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    try:
        # 2. ì¸ì¦ ë° ì‹œíŠ¸ ì—°ê²°
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds_dict = json.loads(json_str) 
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)

        # íŒŒì¼ëª… ì •í™•íˆ ì…ë ¥
        sheet = client.open("QuantLab Subscribers").sheet1
        data = sheet.get_all_records()
        
        active_emails = []
        today = datetime.now().strftime("%Y-%m-%d")

        for row in data:
            email = row.get('email')        
            end_date = row.get('end_date')
            canceled_at = row.get('canceled_at') 

            # ì·¨ì†Œ ë‚ ì§œê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸ (ë¹„ì–´ìˆìœ¼ë©´ True)
            is_canceled = str(canceled_at).strip() != ""
            
            # ì´ë©”ì¼ ì¡´ì¬ + ë§Œë£Œ ì•ˆ ë¨ + ì·¨ì†Œ ì•ˆ í•¨
            if email and end_date and not is_canceled:
                if end_date >= today:
                    active_emails.append(email)
                else:
                    print(f"  ğŸš« ë§Œë£Œëœ êµ¬ë…ì ì œì™¸: {email}")
            elif is_canceled:
                print(f"  ğŸ‘‹ êµ¬ë… ì·¨ì†Œì(ë°œì†¡ ì œì™¸): {email}")
        
        print(f"âœ… í™œì„± êµ¬ë…ì {len(active_emails)}ëª… ì¶”ì¶œ ì™„ë£Œ.")
        return active_emails

    except Exception as e:
        print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

# -----------------------------------------------------------
# ìˆ˜ì‹ ì ëª©ë¡ í†µí•© (í™˜ê²½ë³€ìˆ˜ + êµ¬ê¸€ì‹œíŠ¸)
# -----------------------------------------------------------
# 1. í™˜ê²½ë³€ìˆ˜(ê´€ë¦¬ì) ì´ë©”ì¼ ì²˜ë¦¬
env_emails = os.environ.get("RECEIVER_EMAILS", "")
admin_list = [e.strip().lower() for e in env_emails.split(",") if e.strip()]

# 2. êµ¬ê¸€ ì‹œíŠ¸ êµ¬ë…ì ì´ë©”ì¼ ì²˜ë¦¬
raw_subscribers = get_active_subscribers()
subscriber_list = [e.strip().lower() for e in raw_subscribers if e and e.strip()]

# 3. í•©ì¹˜ê¸° ë° ì¤‘ë³µ ì œê±°
unique_emails = set(admin_list + subscriber_list)

# 4. ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³€í™˜
RECEIVER_EMAILS = list(unique_emails)

print(f"ğŸ“© ìµœì¢… ë°œì†¡ ëŒ€ìƒ(ì¤‘ë³µ ì œê±°ë¨): {len(RECEIVER_EMAILS)}ëª…")
# ë””ë²„ê¹…ìš©: ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ í™•ì¸ (ë¡œê·¸ì—ëŠ” ë‚¨ì§€ë§Œ ë³´ì•ˆìƒ ì£¼ì˜)

AVAILABLE_MODELS = [
    "models/gemini-2.5-flash",
    "models/gemini-2.5-flash-lite",
]

# API í‚¤ ì„¤ì •
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    print("âŒ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

TARGET_SITES = [
    # 1. ê¸€ë¡œë²Œ ìì‚°ìš´ìš©ì‚¬ (ì¸í”„ë¼/PE íŠ¹í™”)
    "blackrock.com",    
    "macquarie.com",     
    "kkr.com",         
    "brookfield.com",    
    
    # 2. ê¸€ë¡œë²Œ íˆ¬ìì€í–‰ (IB - Market Outlook)
    "goldmansachs.com", 
    "jpmorgan.com", 
    "morganstanley.com",
    "ubs.com",          
    
    # 3. ì»¨ì„¤íŒ… ë° ë¦¬ì„œì¹˜ (ì‚°ì—… íŠ¸ë Œë“œ)
    "mckinsey.com", 
    "pwc.com",
    "bain.com",         
    "deloitte.com",    
    
    # 4. êµ­ì œê¸°êµ¬ (ê±°ì‹œê²½ì œ/ì •ì±…)
    "worldbank.org", 
    "adb.org",           
    "imf.org"            
]

SEARCH_KEYWORD = "Infrastructure Outlook"

# ==========================================
# 2. ê¸°ëŠ¥ í•¨ìˆ˜
# ==========================================

def get_kst_now():
    return datetime.now(timezone(timedelta(hours=9)))

def search_pdf_reports(keyword, sites):
    site_query = " OR ".join([f"site:{site}" for site in sites])
    # ê²€ìƒ‰ ë‚ ì§œ í•„í„° (ìµœê·¼ 3ê°œì›” ë“± ìœ ë™ì  ì¡°ì • ê°€ëŠ¥, ì—¬ê¸°ì„  ê²€ìƒ‰ APIì˜ dateRestrict ì‚¬ìš©)
    final_query = f"{keyword} filetype:pdf ({site_query})"
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘... (íƒ€ê²Ÿ: {len(sites)}ê³³)")

    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_SEARCH_API_KEY,
        'cx': SEARCH_ENGINE_ID,
        'q': final_query,
        'num': 10, # ê²€ìƒ‰ ê°œìˆ˜ ì¡°ì ˆ
        'dateRestrict': 'w1' 
    }
    try:
        response = requests.get(url, params=params).json()
        pdf_links = []
        if 'items' in response:
            for item in response['items']:
                pdf_links.append({'title': item['title'], 'link': item['link']})
        return pdf_links
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì—ëŸ¬: {e}")
        return []

def extract_text_fast(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
            'Referer': 'https://www.google.com/'
        }
        response = requests.get(url, headers=headers, timeout=15)

        if response.status_code != 200:
            print(f"   ğŸ’¨ íŒ¨ìŠ¤ (ì ‘ê·¼ ë¶ˆê°€: {response.status_code})")
            return None

        if len(response.content) < 1000:
            print("   ğŸ’¨ íŒ¨ìŠ¤ (íŒŒì¼ ë„ˆë¬´ ì‘ìŒ)")
            return None

        f = io.BytesIO(response.content)
        reader = PdfReader(f)

        if reader.is_encrypted:
            print("   ğŸ”’ íŒ¨ìŠ¤ (ì•”í˜¸í™”ë¨)")
            return None

        text = ""
        # ì• 15í˜ì´ì§€ë§Œ ì½ê¸° (í† í° ì ˆì•½ ë° ì†ë„)
        pages_to_read = min(len(reader.pages), 15)
        for page_num in range(pages_to_read):
            extract = reader.pages[page_num].extract_text()
            if extract: text += extract
                
        if len(text.strip()) < 50:
            print("   âš ï¸ íŒ¨ìŠ¤ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ - ìŠ¤ìº”ë³¸ ì˜ì‹¬)")
            return None

        return text

    except requests.exceptions.Timeout:
        print("   â° íŒ¨ìŠ¤ (15ì´ˆ ì´ˆê³¼)")
        return None
    except Exception:
        print("   âŒ íŒ¨ìŠ¤ (ë‹¤ìš´ë¡œë“œ ì—ëŸ¬)")
        return None

def generate_with_rotation(prompt):
    start_time = time.time()
    print(f"      â–¶ï¸ AI ëª¨ë¸ í˜¸ì¶œ ì¤‘...", flush=True)

    for i, model_name in enumerate(AVAILABLE_MODELS):
        try:
            print(f"      â³ [ì‹œë„ {i+1}] {model_name}...", end=" ", flush=True)
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            elapsed = time.time() - start_time
            print(f"âœ… ì„±ê³µ ({elapsed:.1f}ì´ˆ)", flush=True)
            return response.text, model_name
        except Exception as e:
            print(f"\n      âŒ ì‹¤íŒ¨ ({model_name}): {e}", flush=True)
            time.sleep(1)
            continue

    return "ë¶„ì„ ì‹¤íŒ¨", "None"

# ì›¹ì‚¬ì´íŠ¸ìš© ë§ˆí¬ë‹¤ìš´ ì €ì¥ í•¨ìˆ˜
def save_to_markdown(content,full_content):
    # 1. í´ë” ìƒì„± (data í´ë”ì™€ ê·¸ ì•ˆì— archive í´ë”ê¹Œì§€)
    if not os.path.exists('data/archive'):
        os.makedirs('data/archive')
        
    # [ì €ì¥ 1] ë©”ì¸ í™”ë©´ìš© (í•­ìƒ ë®ì–´ì”Œì›€ -> ìµœì‹  ìœ ì§€)
    with open("data/daily_report.md", "w", encoding="utf-8") as f:
        f.write(content)
        
    # [ì €ì¥ 2] ê¸°ë¡ ë³´ê´€ìš© (ë‚ ì§œê°€ ì´ë¦„ì— ë“¤ì–´ê° -> ì•ˆ ì§€ì›Œì§)
    # íŒŒì¼ëª… ì˜ˆì‹œ: data/archive/2025-12-19_report.md
    today_str = get_kst_now().strftime('%Y-%m-%d')
    archive_path = f"data/archive/{today_str}_report.md"
    
    with open(archive_path, "w", encoding="utf-8") as f:
        f.write(full_content)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: daily_report.md ë° {today_str}_report.md")

def send_email(subject, body):
    if not GMAIL_USER or not GMAIL_APP_PWD: 
        print("âŒ ì´ë©”ì¼ ì„¤ì •ì´ ì—†ì–´ ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    if not RECEIVER_EMAILS: return

    msg = MIMEMultipart()
    msg['From'] = GMAIL_USER
    msg['To'] = ", ".join(RECEIVER_EMAILS)
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))

    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(GMAIL_USER, GMAIL_APP_PWD)
        server.send_message(msg)
        server.quit()
        print(f"   ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ (ì´ {len(RECEIVER_EMAILS)}ëª…)")
    except Exception as e:
        print(f"   âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    print(f"ğŸš€ '{SEARCH_KEYWORD}' ê³ ì† ë¶„ì„ ì‹œì‘...\n")

    reports = search_pdf_reports(SEARCH_KEYWORD, TARGET_SITES)

    if not reports:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        # ì‹¤íŒ¨ ì‹œì—ë„ ë¹ˆ íŒŒì¼ì´ë¼ë„ ë§Œë“¤ì–´ì•¼ ì—ëŸ¬ ë°©ì§€ ê°€ëŠ¥
        save_to_markdown("ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ë¦¬í¬íŠ¸ê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        success_count = 0
        collected_insights = []

        for i, report in enumerate(reports):
            print(f"\n[{i+1}/{len(reports)}] í™•ì¸ ì¤‘: {report['title'][:30]}...")

            pdf_text = extract_text_fast(report['link'])

            if pdf_text and len(pdf_text) > 500:
                print("   ğŸ“ í…ìŠ¤íŠ¸ í™•ë³´! ë¶„ì„ ì‹œì‘...")

                prompt = f"""ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìµœìƒìœ„ 'ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ì „ëµê°€'ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤. ë˜í•œ ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

[ë³´ê³ ì„œ ì •ë³´]
ì œëª©: {report['title']}

[ë¶„ì„ ì§€ì¹¨]
1. ì¼ë°˜ì ì¸ ë‚´ìš©ì€ ì œê±°í•˜ê³ , êµ¬ì²´ì ì´ê³  ë‚ ì¹´ë¡œìš´ í†µì°° ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
2. ëª¨ë“  ì£¼ì¥ì€ ë³´ê³ ì„œ ë‚´ì˜ 'ìˆ«ì'ë‚˜ 'ì‚¬ë¡€'ë¡œ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

[ì¶œë ¥ í˜•ì‹ (Markdown)]
### 1. ğŸš¨ í•µì‹¬ ì‹œì¥ ë³€í™”
* (ë‚´ìš©)

### 2. ğŸ©¸ ê³ í†µê³¼ ê¸°íšŒ
* (ë‚´ìš©)

### 3. ğŸ“Š í•„ìˆ˜ ë°ì´í„°
* (ë‚´ìš©)

### 4. ğŸ’° ìœ ë§ ì„¹í„°
* (ë‚´ìš©)

[í…ìŠ¤íŠ¸]:
{pdf_text[:30000]}
"""
                insight, model_used = generate_with_rotation(prompt)

                summary = f"ğŸ“„ **{report['title']}**\nğŸ”— {report['link']}\n{insight}\n"
                collected_insights.append(summary)
                success_count += 1

                time.sleep(2)
            else:
                pass

        if collected_insights:
            print(f"\nğŸ‰ ì´ {success_count}ê±´ ì„±ê³µ! ì¢…í•© ë¶„ì„ ì¤‘...")
            
            # 1. ê°œë³„ ìš”ì•½ë³¸ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
            all_summaries_text = "\n\n---\n".join(collected_insights)
            
            # (í”„ë¡¬í”„íŠ¸ì—ëŠ” ìš”ì•½ë³¸ì„ ë³´ì—¬ì£¼ê¸°ë§Œ í•˜ê³ , ì¶œë ¥ í¬ë§·ì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ)
            final_prompt = f"""
ë‹¹ì‹ ì€ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
ì•„ë˜ ì œê³µëœ {success_count}ê°œì˜ [ê°œë³„ ë¦¬í¬íŠ¸ ìš”ì•½ë³¸]ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ì‹­ì‹œì˜¤.
ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

[ë¶„ì„ ì§€ì¹¨]
1. ìƒí˜¸ ê²€ì¦: ì—¬ëŸ¬ ë³´ê³ ì„œì˜ ê³µí†µëœ í•©ì˜(Consensus)ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤.
2. ì´ê²¬: ì „ë§ì´ ì—‡ê°ˆë¦¬ëŠ” ë¶€ë¶„ì€ ë¦¬ìŠ¤í¬ë¡œ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
3. í° ê·¸ë¦¼: ê°œë³„ ì‚¬ê±´ë“¤ì„ ì—°ê²°í•˜ì—¬ ê±°ì‹œì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì‹­ì‹œì˜¤.

[ê°œë³„ ë¦¬í¬íŠ¸ ìš”ì•½ë³¸ ë°ì´í„°]:
{all_summaries_text}

[ì¶œë ¥ í˜•ì‹ (Markdown)]
# ğŸŒ Global Market Synthesis Report ({get_kst_now().strftime('%Y-%m-%d')})

## 1. Executive Summary
* (í•µì‹¬ ë©”ì‹œì§€ í•œ ë¬¸ì¥)

## 2. Mega Trends
* (ê³µí†µëœ ê±°ëŒ€í•œ ë³€í™” 3ê°€ì§€)

## 3. Alpha Opportunities (ì´ˆê³¼ ìˆ˜ìµ ê¸°íšŒ)
* (êµ¬ì²´ì  ê·¼ê±° í¬í•¨)

## 4. Risk Assessment
* (í•˜ë°© ìœ„í—˜ ìš”ì¸)
"""
            # 2. AIì—ê²Œ ì¢…í•© ë¶„ì„
            final_insight, final_model = generate_with_rotation(final_prompt)
            
            footer = """
\n\n
--------------------------------------------------
* ë³¸ ë©”ì¼ì€ Quant Lab êµ¬ë… ì„œë¹„ìŠ¤ì˜ ì¼í™˜ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.
* ìˆ˜ì‹ ì„ ì›ì¹˜ ì•Šìœ¼ì‹œë©´ ì›¹ì‚¬ì´íŠ¸ì˜ [êµ¬ë… ì·¨ì†Œ] íƒ­ì„ ì´ìš©í•´ì£¼ì„¸ìš”.
--------------------------------------------------
"""
            
            # 3. AIì˜ ì¢…í•© ë¶„ì„ ë’¤ì— ê°œë³„ ë¦¬í¬íŠ¸ ìš”ì•½ì„ ìˆ˜ë™ìœ¼ë¡œ ë¶™ì„
            final_report_content = f"{final_insight}\n\n---\n## ğŸ“š Individual Report Summaries\n(ì•„ë˜ ë‚´ìš©ì€ ê°œë³„ ë¦¬í¬íŠ¸ì˜ ìš”ì•½ì…ë‹ˆë‹¤)\n\n{all_summaries_text} {footer}"

            # 4. ì €ì¥ ë° ì „ì†¡(ì›¹ì‚¬ì´íŠ¸ì—ëŠ” ìµœì¢… ìš”ì•½ë³¸ë§Œ, ë©”ì¼ ë° DBì—ëŠ” ê°œë³„ ë¦¬í¬íŠ¸ í¬í•¨)
            save_to_markdown(final_insight,final_report_content)
            send_email(f"[Quant-Lab] {SEARCH_KEYWORD} ì¢…í•© ë¦¬í¬íŠ¸", final_report_content)
            
            print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
            
        else:
            print("\nâŒ ë¶„ì„ ì„±ê³µí•œ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            save_to_markdown("ë¶„ì„ ê°€ëŠ¥í•œ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
