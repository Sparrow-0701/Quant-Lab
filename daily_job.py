import os
import io
import time
import smtplib
import requests
import toml
import google.generativeai as genai
from pypdf import PdfReader
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta, timezone # timezone í•„ìˆ˜
from supabase import create_client

# ==========================================
# 1. í™˜ê²½ ì„¤ì •
# ==========================================

# í•œêµ­ ì‹œê°„ëŒ€(KST) ì •ì˜ - ì„œë²„ì—ì„œë„ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ëœ¨ê²Œ í•¨
KST = timezone(timedelta(hours=9))

try:
    # 1. ë¡œì»¬ ê°œë°œ í™˜ê²½
    current_dir = os.path.dirname(os.path.abspath(__file__))
    secrets_path = os.path.join(current_dir, ".streamlit", "secrets.toml")
    
    if os.path.exists(secrets_path):
        secrets = toml.load(secrets_path)
        SUPABASE_URL = secrets["supabase"]["SUPABASE_URL"]
        SUPABASE_KEY = secrets["supabase"]["SUPABASE_KEY"]
        GEMINI_API_KEY = secrets.get("google", {}).get("GEMINI_API_KEY")
        GOOGLE_SEARCH_API_KEY = secrets.get("google", {}).get("GOOGLE_SEARCH_API_KEY")
        SEARCH_ENGINE_ID = secrets.get("google", {}).get("SEARCH_ENGINE_ID") 
        GMAIL_USER = secrets["GMAIL"]["GMAIL_USER"]
        GMAIL_APP_PWD = secrets["GMAIL"]["GMAIL_APP_PWD"]
    else:
        # 2. GitHub Actions í™˜ê²½
        SUPABASE_URL = os.environ.get("SUPABASE_URL")
        SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
        GOOGLE_SEARCH_API_KEY = os.environ.get("GOOGLE_SEARCH_API_KEY")
        SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID")
        GMAIL_USER = os.environ.get("GMAIL_USER")
        GMAIL_APP_PWD = os.environ.get("GMAIL_APP_PWD")

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    genai.configure(api_key=GEMINI_API_KEY)

except Exception as e:
    print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# ê²€ìƒ‰ ëŒ€ìƒ ë° í‚¤ì›Œë“œ
TARGET_SITES = [
    "blackrock.com", "macquarie.com", "kkr.com", "brookfield.com",
    "goldmansachs.com", "jpmorgan.com", "morganstanley.com", "ubs.com",
    "mckinsey.com", "pwc.com", "bain.com", "deloitte.com",
    "worldbank.org", "adb.org", "imf.org"
]
SEARCH_KEYWORD = "Infrastructure Outlook"

# ==========================================
# 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜
# ==========================================

def get_subscribers_from_db(lang_code=None):
    try:
        query = supabase.table("subscribers").select("email").eq("is_active", True)
        if lang_code:
            query = query.eq("language", lang_code)
        response = query.execute()
        return [row['email'] for row in response.data]
    except Exception as e:
        print(f"âŒ êµ¬ë…ì DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def search_pdf_reports(keyword, sites):
    if not GOOGLE_SEARCH_API_KEY or not SEARCH_ENGINE_ID:
        print("âš ï¸ ê²€ìƒ‰ API í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []
        
    site_query = " OR ".join([f"site:{site}" for site in sites])
    final_query = f"{keyword} filetype:pdf ({site_query})"
    
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_SEARCH_API_KEY,
        'cx': SEARCH_ENGINE_ID,
        'q': final_query,
        'num': 10,
        'dateRestrict': 'w1'
    }
    try:
        res = requests.get(url, params=params).json()
        return [{'title': i['title'], 'link': i['link']} for i in res.get('items', [])]
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def extract_text_fast(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200: return None
        
        f = io.BytesIO(response.content)
        reader = PdfReader(f)
        text = ""
        for i in range(min(len(reader.pages), 10)):
            text += reader.pages[i].extract_text() or ""
        return text if len(text) > 500 else None
    except:
        return None

def generate_synthesis(summaries_text, lang='ko'):
    model = genai.GenerativeModel('gemini-2.5-flash') 
    
    # [ìˆ˜ì •] ë‚ ì§œë¥¼ KST ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
    today_kst = datetime.now(KST).strftime('%Y-%m-%d')
    
    if lang == 'en':
        prompt = f"""
        Role: CIO of a Global Macro Hedge Fund.
        Task: Curate a "Daily Market Intelligence Dashboard" from the provided report summaries.
        Target Audience: Traders reading on mobile. Needs to be "At-a-Glance" readable.

        [Input Summaries]:
        {summaries_text}

        [Constraints]:
        1. **Aggressive Curation**: Do not summarize everything. Pick the "Highest Conviction" calls from the inputs.
        2. **Ticker Extraction**: You MUST extract specific tickers (e.g., $NVDA, $TSLA) mentioned in the reports and list them clearly.
        3. **Visual Structure**: Use dividers, bold text for numbers, and emojis to create a "Dashboard" feel.

        [Output Format (Markdown)]:
        # â˜• Market Briefing ({today_kst})

        ## ğŸš¦ Market Sentiment Meter
        (Create a visual text gauge based on overall tone)
        Example: [ğŸ”´ Fear ---âšª Neutral ---ğŸŸ¢ Greed]
        * **Verdict**: (One word: e.g., "Bullish", "Cautious", "Panic")
        * **Driver**: (1 sentence on why)

        ---

        ## ğŸ† Top High-Conviction Calls (Must Read)
        (Aggregate the specific 'Long/Overweight' ideas from input reports)
        | Ticker | Strategy | Key Rationale |
        | :--- | :--- | :--- |
        | **$TICKER** | Long/Short | (Short phrase, e.g., "Strong AI Demand") |
        | **$TICKER** | Long/Short | (Short phrase) |
        *(If no specific tickers, mention top sectors)*

        ---

        ## âš¡ 3-Minute Macro Digest
        * **ğŸŒ Global Theme**: (Dominant narrative)
        * **âš ï¸ Risk Radar**: (Biggest threat today)
        * **ğŸ“Š Key Data**: (Most important number, e.g., "CPI 3.2%")

        ## ğŸ¦„ The "Hidden Gem" Insight
        * (A unique/contrarian idea found in the reports that others might miss)
        """
    else:
        prompt = f"""
        ì—­í• : ê¸€ë¡œë²Œ ë§¤í¬ë¡œ í—¤ì§€í€ë“œ CIO.
        ì„ë¬´: ê°œë³„ ë¦¬í¬íŠ¸ë“¤ì„ ì¢…í•©í•˜ì—¬, í•µì‹¬ ì¢…ëª©ê³¼ ì „ëµì´ í•œëˆˆì— ë³´ì´ëŠ” 'ëª¨ë°”ì¼ ë§ˆì¼“ ëŒ€ì‹œë³´ë“œ'ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        ë…ì: ì¶œê·¼ê¸¸ 1ë¶„ ì•ˆì— ëˆì´ ë˜ëŠ” ì •ë³´ë¥¼ ì°¾ìœ¼ë ¤ëŠ” íŠ¸ë ˆì´ë”.

        [ì…ë ¥ ìš”ì•½ë³¸]:
        {summaries_text}

        [ì œì•½ ì‚¬í•­]:
        1. **ì² ì €í•œ íë ˆì´ì…˜**: ëª¨ë“  ë‚´ìš©ì„ ë‚˜ì—´í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ê°€ì¥ í™•ì‹ (Conviction)ì´ ë†’ì€ íˆ¬ì ì•„ì´ë””ì–´ë§Œ ì„ ë³„í•˜ì‹­ì‹œì˜¤.
        2. **í‹°ì»¤($) í•„ìˆ˜ ë…¸ì¶œ**: ì…ë ¥ ë°ì´í„°ì— ìˆëŠ” êµ¬ì²´ì ì¸ ì¢…ëª©ëª…(ì˜ˆ: $NVDA, $SOXL)ì„ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ì—¬ 'Top Picks' ì„¹ì…˜ì— ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.
        3. **ì‹œê°ì  êµ¬ì¡°**: ì¤„ê¸€ ëŒ€ì‹  í‘œ(Table)ë‚˜ ì§§ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ê·¹ëŒ€í™”í•˜ì‹­ì‹œì˜¤.

        [ì¶œë ¥ ì–‘ì‹ (Markdown)]:
        # â˜• ëª¨ë‹ ë§ˆì¼“ ë¸Œë¦¬í•‘ ({today_kst})

        ## ğŸš¦ ì‹œì¥ ì‹¬ë¦¬ ë¯¸í„°ê¸° (Market Meter)
        (ì „ë°˜ì ì¸ ë¦¬í¬íŠ¸ ë¶„ìœ„ê¸°ë¥¼ í…ìŠ¤íŠ¸ ê²Œì´ì§€ë¡œ í‘œí˜„)
        ì˜ˆì‹œ: [ğŸ”´ ê³µí¬(Fear) -----âšª ì¤‘ë¦½ -----ğŸŸ¢ íƒìš•(Greed)]
        * **ì˜¤ëŠ˜ì˜ í•œë§ˆë””**: (ì˜ˆ: "ì €ê°€ ë§¤ìˆ˜ ê¸°íšŒ", "ì†Œë‚˜ê¸°ëŠ” í”¼í•˜ì")
        * **í•µì‹¬ ì´ìœ **: (1ë¬¸ì¥ ìš”ì•½)

        ---

        ## ğŸ† ì˜¤ëŠ˜ì˜ Top Picks (ì£¼ëª©í•  ì¢…ëª©)
        (ì…ë ¥ëœ ë¦¬í¬íŠ¸ë“¤ì˜ 'Long/Overweight' ì˜ê²¬ì„ ì¢…í•©í•˜ì—¬ í…Œì´ë¸”ë¡œ ì •ë¦¬)
        | ì¢…ëª©($) | í¬ì§€ì…˜ | í•µì‹¬ ë…¼ê±° (ì§§ê²Œ) |
        | :--- | :--- | :--- |
        | **$í‹°ì»¤** | ë§¤ìˆ˜/ë§¤ë„ | (ì˜ˆ: AI ìˆ˜ìš” í­ë°œ ì§€ì†) |
        | **$í‹°ì»¤** | ë§¤ìˆ˜/ë§¤ë„ | (ì˜ˆ: ê¸ˆë¦¬ ì¸í•˜ ìˆ˜í˜œ) |
        *(íŠ¹ì • ì¢…ëª©ì´ ì—†ë‹¤ë©´ ìœ ë§ ì„¹í„° ê¸°ì¬)*

        ---

        ## âš¡ 3ë¶„ ë§¤í¬ë¡œ ìš”ì•½
        * **ğŸŒ í•µì‹¬ í…Œë§ˆ**: (ì‹œì¥ì„ ì›€ì§ì´ëŠ” ë©”ì¸ ì´ìŠˆ)
        * **âš ï¸ ë¦¬ìŠ¤í¬ ë ˆì´ë”**: (ì˜¤ëŠ˜ ì¡°ì‹¬í•´ì•¼ í•  í•˜ë°© ìš”ì¸)
        * **ğŸ“Š ë°ì´í„° ì²´í¬**: (ì£¼ëª©í•´ì•¼ í•  ì§€í‘œ/ìˆ˜ì¹˜)

        ## ğŸ¦„ í‹ˆìƒˆ/ì—­ë°œìƒ ì•„ì´ë””ì–´ (Hidden Gem)
        * (ë‚¨ë“¤ì´ ë³´ì§€ ëª»í•œ ë…íŠ¹í•œ ì¸ì‚¬ì´íŠ¸ 1ê°€ì§€)
        """
        
    try:
        res = model.generate_content(prompt)
        return res.text
    except Exception as e:
        return f"ë¶„ì„ ì‹¤íŒ¨: {e}"

def send_email_batch(subject, body, receivers):
    if not receivers: return
    
    msg = MIMEMultipart()
    sender_name = "RevolTac" 
    msg['From'] = f"{sender_name} <{GMAIL_USER}>"
    msg['Subject'] = subject
    msg['Bcc'] = ", ".join(receivers) 
    msg.attach(MIMEText(body, 'plain'))

    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(GMAIL_USER, GMAIL_APP_PWD)
        server.send_message(msg)
        server.quit()
        print(f"âœ… ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ ({len(receivers)}ëª…)")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

# ==========================================
# 3. ë©”ì¸ ë¡œì§
# ==========================================
if __name__ == "__main__":
    print("ğŸš€ QuantLab Daily Job ì‹œì‘...")
    
    reports = search_pdf_reports(SEARCH_KEYWORD, TARGET_SITES)
    
    structured_summaries = [] 
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    # 2. ê°œë³„ ë¦¬í¬íŠ¸ ìš”ì•½
    for report in reports:
        print(f"Processing: {report['title']}...")
        
        text = extract_text_fast(report['link'])
        
        if text:
            try:
                prompt_ko = f"""
                ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ í€€íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
                ì£¼ì–´ì§„ ë¦¬í¬íŠ¸ë¥¼ PMì´ ì¦‰ì‹œ í™œìš©í•  ìˆ˜ ìˆëŠ” 'êµ¬ì¡°í™”ëœ ë°ì´í„° ì¹´ë“œ'ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.

                [ì…ë ¥ í…ìŠ¤íŠ¸]:
                {text}

                [ë¶„ì„ ì§€ì¹¨]:
                1. **Ticker ê°•ì œ ì¶”ì¶œ**: ì¢…ëª©ëª…ì€ ë°˜ë“œì‹œ í‹°ì»¤ í˜•íƒœ(ì˜ˆ: $TSLA)ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¬í•˜ì‹­ì‹œì˜¤.
                2. **ëª…í™•í•œ êµ¬ë¶„**: íŒ©íŠ¸(Fact)ì™€ ì˜ê²¬(Opinion)ì„ êµ¬ë¶„í•˜ê³ , ìˆ˜ì¹˜(Numbers) ìœ„ì£¼ë¡œ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
                3. **ê°„ê²°í•¨**: ëª¨ë°”ì¼ì—ì„œ ì½ê¸° ì¢‹ê²Œ ë¬¸ì¥ì„ ì§§ê²Œ ëŠìœ¼ì‹­ì‹œì˜¤.

                [ì¶œë ¥ ì–‘ì‹ (Markdown)]:
                ### ğŸ“„ [ë¦¬í¬íŠ¸ ì œëª©/ì£¼ì œ] ë¶„ì„
                * **ğŸ’¡ One-Liner**: (í•µì‹¬ ë…¼ë¦¬ 1ë¬¸ì¥)
                * **ğŸŒ¡ï¸ Sentiment**: [ì ìˆ˜ -5 ~ +5]

                #### ğŸ¯ í•µì‹¬ íˆ¬ì ì•„ì´ë””ì–´ (Key Calls)
                * **ğŸŸ¢ Long (ë§¤ìˆ˜/ë¹„ì¤‘í™•ëŒ€)**:
                - **$TICKER**: (ëª©í‘œê°€ í˜¹ì€ íˆ¬ì í¬ì¸íŠ¸)
                - **$TICKER**: (ëª©í‘œê°€ í˜¹ì€ íˆ¬ì í¬ì¸íŠ¸)
                * **ğŸ”´ Short (ë§¤ë„/ë¦¬ìŠ¤í¬)**:
                - **$TICKER**: (ë¦¬ìŠ¤í¬ ìš”ì¸)

                #### ğŸ”¢ í•µì‹¬ ë°ì´í„° (Key Numbers)
                * (ì¤‘ìš” ìˆ˜ì¹˜ 1)
                * (ì¤‘ìš” ìˆ˜ì¹˜ 2)
                """
                
                res_ko = model.generate_content(prompt_ko)
                
                prompt_en = f"""
                Role: Senior Quant Analyst.
                Task: Convert the report into a 'Structured Data Card' for immediate PM use.

                [Input Text]:
                {text}

                [Guidelines]:
                1. **Force Tickers**: Always convert company names to Tickers (e.g., $TSLA).
                2. **Conciseness**: Short bullets only. Focus on Numbers (%, $).

                [Output Format (Markdown)]:
                ### ğŸ“„ Report Analysis
                * **ğŸ’¡ One-Liner**: (Core thesis in 1 sentence)
                * **ğŸŒ¡ï¸ Sentiment**: [Score -5 to +5]

                #### ğŸ¯ Key Investment Calls
                * **ğŸŸ¢ Long/Overweight**:
                - **$TICKER**: (Target Price / Catalyst)
                * **ğŸ”´ Short/Underweight**:
                - **$TICKER**: (Risk Factors)

                #### ğŸ”¢ Key Numbers
                * (Critical Metric 1)
                * (Critical Metric 2)
                """
                res_en = model.generate_content(prompt_en)
                
                # DB ì €ì¥
                supabase.table("individual_reports").insert({
                    "title": report['title'],
                    "link": report['link'],
                    "summary_ko": res_ko.text,
                    "summary_en": res_en.text
                }).execute()
                
                structured_summaries.append({
                    "title": report['title'],
                    "link": report['link'],
                    "summary_ko": res_ko.text,
                    "summary_en": res_en.text
                })
                
                time.sleep(2) 
                
            except Exception as e:
                print(f"Error processing {report['title']}: {e}")

    if structured_summaries:
        all_text_en = "\n\n".join([f"Title: {s['title']}\nSummary: {s['summary_en']}" for s in structured_summaries])
        
        print("ğŸ¤– ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        final_ko = generate_synthesis(all_text_en, 'ko')
        final_en = generate_synthesis(all_text_en, 'en')
        
        # ë‚ ì§œë¥¼ KST ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
        today_kst_str = datetime.now(KST).strftime('%Y-%m-%d')
        today_kst_md = datetime.now(KST).strftime('%m/%d')
        
        # DB ì €ì¥ 
        db_data = {
            "title": f"Global Market Synthesis ({today_kst_str})",
            "summary_ko": final_ko,
            "summary_en": final_en
        }
        supabase.table("daily_reports").insert(db_data).execute()
        print("ğŸ’¾ ì¢…í•© ë¦¬í¬íŠ¸ DB ì €ì¥ ì™„ë£Œ!")

        # ë©”ì¼ ë³¸ë¬¸ ì¡°ë¦½
        def build_mail_body(synthesis, summaries, lang='ko'):
            body = f"{synthesis}\n\n"
            body += "=" * 40 + "\n\n"
            
            if lang == 'ko':
                body += "ğŸ“š [ì°¸ê³ í•œ ê°œë³„ ë¦¬í¬íŠ¸ ì›ë¬¸ ìš”ì•½]\n\n"
                key = 'summary_ko'
            else:
                body += "ğŸ“š [Individual Report Summaries]\n\n"
                key = 'summary_en'

            for item in summaries:
                body += f"ğŸ“Œ {item['title']}\n"
                body += f"ğŸ”— {item['link']}\n"
                body += f"{item[key]}\n" 
                body += "-" * 20 + "\n"
            
            return body

        # ë©”ì¼ ë°œì†¡
        korean_users = get_subscribers_from_db('ko')
        if korean_users:
            body_ko = build_mail_body(final_ko, structured_summaries, 'ko')
            send_email_batch(f"[QuantLab] ì˜¤ëŠ˜ì˜ ê¸€ë¡œë²Œ ë§ˆì¼“ ë¸Œë¦¬í•‘ ({today_kst_md})", body_ko, korean_users)

        english_users = get_subscribers_from_db('en')
        if english_users:
            body_en = build_mail_body(final_en, structured_summaries, 'en')
            send_email_batch(f"[QuantLab] Daily Market Brief ({today_kst_md})", body_en, english_users)
            
    else:
        print("ğŸ’¤ ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
